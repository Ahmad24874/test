################################################################                          WARNING!!!!                        ## This is a sandbox environment. Using personal credentials   ## is HIGHLY! discouraged. Any consequences of doing so are    ## completely the user's responsibilites.                      ##                                                             ## The PWD team.                                               ################################################################[node1] (local) root@192.168.0.22 ~$ docker swarm init --advertise-addr $(hostname -i)
Swarm initialized: current node (j70h3ty7rb1ksz7eeqkvwn6wz) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-2i77rbjajgylhb9k7jow5xgyoha9fxy3zdkqb0b6ou39qko2b4-2ae1rvrga40juhvp0q064e8tf 192.168.0.22:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.

[node1] (local) root@192.168.0.22 ~
$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
j70h3ty7rb1ksz7eeqkvwn6wz *   node1               Ready               Active              Leader              19.03.4
tir91iht85gyii8cpjbulvq4q     node2               Ready               Active                                  19.03.4
[node1] (local) root@192.168.0.22 ~
$ git clone https://github.com/Ahmad24874/test
Cloning into 'test'...
remote: Enumerating objects: 58, done.
remote: Counting objects: 100% (58/58), done.
remote: Compressing objects: 100% (50/50), done.
remote: Total 58 (delta 10), reused 0 (delta 0), pack-reused 0
Unpacking objects: 100% (58/58), done.
[node1] (local) root@192.168.0.22 ~
$ cd test
[node1] (local) root@192.168.0.22 ~/test
$ ls
test
[node1] (local) root@192.168.0.22 ~/test
$ cd test
[node1] (local) root@192.168.0.22 ~/test/test
$ ls
README.md           instagram.py        www
api                 linkextractor
docker-compose.yml  packetsniffer.py
[node1] (local) root@192.168.0.22 ~/test/test
$ docker stack deploy --compose-file=docker-compose.yml wikistack
Ignoring unsupported options: build

Creating network wikistack_default
Creating service wikistack_api
Creating service wikistack_web
Creating service wikistack_redis
[node1] (local) root@192.168.0.22 ~/test/test
$ docker stack ls
NAME                SERVICES            ORCHESTRATOR
wikistack           3                   Swarm
[node1] (local) root@192.168.0.22 ~/test/test
$ docker stack services wikistack
ID                  NAME                MODE                REPLICAS        IMAGE                          PORTS
38g3hat87tz6        wikistack_api       replicated          0/1        wikicrawler-api:step5-python   *:5000->5000/tcp
ujj9wuvxvjli        wikistack_redis     replicated          1/1        redis:latest
zkro0rgs8u29        wikistack_web       replicated          0/1        wikicrawler-web:step5-php      *:80->80/tcp
[node1] (local) root@192.168.0.22 ~/test/test
$ docker service ps wikistack
no such service: wikistack
[node1] (local) root@192.168.0.22 ~/test/test
$ docker service ps wikistack_redis
ID                  NAME                IMAGE               NODE        DESIRED STATE       CURRENT STATE                ERROR     PORTS
xi8pgu4ib98v        wikistack_redis.1   redis:latest        node2        Running             Running about a minute ago
[node1] (local) root@192.168.0.22 ~/test/test
$ docker stack services wikistack
ID                  NAME                MODE                REPLICAS        IMAGE                          PORTS
38g3hat87tz6        wikistack_api       replicated          0/1        wikicrawler-api:step5-python   *:5000->5000/tcp
ujj9wuvxvjli        wikistack_redis     replicated          1/1        redis:latest
zkro0rgs8u29        wikistack_web       replicated          0/1        wikicrawler-web:step5-php      *:80->80/tcp
[node1] (local) root@192.168.0.22 ~/test/test
$ docker image ls
REPOSITORY          TAG                 IMAGE ID            CREATED        SIZE
[node1] (local) root@192.168.0.22 ~/test/test
$ docker-compose up -d --build
WARNING: The Docker Engine you're using is running in swarm mode.

Compose does not use swarm mode to deploy services to multiple nodes ina swarm. All containers will be scheduled on the current node.

To deploy your application across the swarm, use `docker stack deploy`.

Creating network "test_default" with the default driver
Building web
Step 1/4 : FROM       php:7-apache
7-apache: Pulling from library/php
68ced04f60ab: Pulling fs layer
1d2a5d8fa585: Pulling fs layer
5d59ec4ae241: Pulling fs layer
d42331ef4d44: Waiting
408b7b7ee112: Pull complete
570cd47896d5: Pull complete
2419413b2a16: Pull complete
2c7832852643: Pull complete
8b0b209a25bc: Pull complete
46011418685f: Pull complete
68be3748ea55: Pull complete
4e3af655ec1e: Pull complete
9f579d3b7159: Pull complete
Digest: sha256:c496c0f962eaaea0f52d9c068bf331fe477703d4657f99b955a2a35a4c3486c4
Status: Downloaded newer image for php:7-apache
 ---> d753d5b380a1
Step 2/4 : LABEL      maintainer="Sawood Alam <@ibnesayeed>"
 ---> Running in aaf4225e7f90
Removing intermediate container aaf4225e7f90
 ---> 3c3eb834ca77
Step 3/4 : ENV        API_ENDPOINT="http://localhost:5000/api/"
 ---> Running in 7eee8c989103
Removing intermediate container 7eee8c989103
 ---> a8a515579f48
Step 4/4 : COPY       . /var/www/html/
 ---> d900099f8cee
Successfully built d900099f8cee
Successfully tagged wikicrawler-web:step5-php
Building api
Step 1/9 : FROM         python:3
3: Pulling from library/python
50e431f79093: Pull complete
dd8c6d374ea5: Pull complete
c85513200d84: Pull complete
55769680e827: Pull complete
f5e195d50b88: Pull complete
94cdd3612287: Pull complete
3b37b69935d4: Pull complete
b9add85f08c4: Pull complete
aa1f4a29beac: Pull complete
Digest: sha256:da4f61227d5facb694293c1356051403d0d163a2d7aa8a0e0d3d9cfc347e3901
Status: Downloaded newer image for python:3
 ---> f88b2f81f83a
Step 2/9 : LABEL                maintainer="Ahmad"
 ---> Running in 7d448da8674c
Removing intermediate container 7d448da8674c
 ---> 59ffd5d80cfb
Step 3/9 : ENV          REDIS_URL="redis://localhost:6379"
 ---> Running in f1329b1b46ca
Removing intermediate container f1329b1b46ca
 ---> ffedb38b4c14
Step 4/9 : WORKDIR              /app
 ---> Running in ab2899bf6b78
Removing intermediate container ab2899bf6b78
 ---> d54e5296cf0b
Step 5/9 : COPY         requirements.txt /app/
 ---> aba4deca5d9c
Step 6/9 : RUN          pip install -r requirements.txt
 ---> Running in ede4713a11ff
Collecting beautifulsoup4
  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)
Collecting flask
  Downloading Flask-1.1.1-py2.py3-none-any.whl (94 kB)
Collecting redis
  Downloading redis-3.4.1-py2.py3-none-any.whl (71 kB)
Collecting wikipedia
  Downloading wikipedia-1.4.0.tar.gz (27 kB)
Collecting requests
  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)
Collecting soupsieve>=1.2
  Downloading soupsieve-2.0-py2.py3-none-any.whl (32 kB)
Collecting Jinja2>=2.10.1
  Downloading Jinja2-2.11.1-py2.py3-none-any.whl (126 kB)
Collecting Werkzeug>=0.15
  Downloading Werkzeug-1.0.0-py2.py3-none-any.whl (298 kB)
Collecting click>=5.1
  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)
Collecting itsdangerous>=0.24
  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)
Collecting idna<3,>=2.5
  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)
Collecting chardet<4,>=3.0.2
  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1
  Downloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)
Collecting certifi>=2017.4.17
  Downloading certifi-2019.11.28-py2.py3-none-any.whl (156 kB)
Collecting MarkupSafe>=0.23
  Downloading MarkupSafe-1.1.1-cp38-cp38-manylinux1_x86_64.whl (32 kB)
Building wheels for collected packages: wikipedia
  Building wheel for wikipedia (setup.py): started
  Building wheel for wikipedia (setup.py): finished with status 'done'
  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11685 sha256=6a541185ee473549f13a6318c02d5b34a28c3cb897cfff499fec0da6f05ff9a0
  Stored in directory: /root/.cache/pip/wheels/07/93/05/72c05349177dca2e0ba31a33ba4f7907606f7ddef303517c6a
Successfully built wikipedia
Installing collected packages: soupsieve, beautifulsoup4, MarkupSafe, Jinja2, Werkzeug, click, itsdangerous, flask, redis, idna, chardet, urllib3, certifi, requests, wikipedia
Successfully installed Jinja2-2.11.1 MarkupSafe-1.1.1 Werkzeug-1.0.0 beautifulsoup4-4.8.2 certifi-2019.11.28 chardet-3.0.4 click-7.0 flask-1.1.1 idna-2.9 itsdangerous-1.1.0 redis-3.4.1 requests-2.23.0 soupsieve-2.0 urllib3-1.25.8 wikipedia-1.4.0
Removing intermediate container ede4713a11ff
 ---> fc7572491bdc
Step 7/9 : COPY         *.py /app/
 ---> 2c5031006ea0
Step 8/9 : RUN          chmod a+x *.py
 ---> Running in 761900733e6d
Removing intermediate container 761900733e6d
 ---> 00ec17459759
Step 9/9 : CMD          ["./main.py"]
 ---> Running in 5fb1ceb0c64d
Removing intermediate container 5fb1ceb0c64d
 ---> e84b30c9330f
Successfully built e84b30c9330f
Successfully tagged wikicrawler-api:step5-python
Pulling redis (redis:)...
latest: Pulling from library/redis
68ced04f60ab: Already exists
7ecc253967df: Pull complete
765957bf98d4: Pull complete
52f16772e1ca: Pull complete
2e43ba99c3f3: Pull complete
d95576c71392: Pull complete
Creating test_redis_1 ...
Creating test_web_1   ... error
Creating test_api_1   ...

ERROR: for test_web_1  Cannot start service web: driver failed programmiCreating test_redis_1 ... donee538359e7120874caf44534322a1475fd09d708c2): Error starting userland proxCreating test_api_1   ... done

ERROR: for web  Cannot start service web: driver failed programming external connectivity on endpoint test_web_1 (0dcde8d8f4a9764f7651e09e538359e7120874caf44534322a1475fd09d708c2): Error starting userland proxy: listen tcp 0.0.0.0:80: bind: address already in use
ERROR: Encountered errors while bringing up the project.
[node1] (local) root@192.168.0.22 ~/test/test
$ docker service scale wikistack_api=5
wikistack_api scaled to 5
overall progress: 5 out of 5 tasks
1/5: running
2/5: running
3/5: running
4/5: running
5/5: running
verify: Service converged
[node1] (local) root@192.168.0.22 ~/test/test
$ docker stack services wikistack
ID                  NAME                MODE                REPLICAS        IMAGE                          PORTS
38g3hat87tz6        wikistack_api       replicated          5/5        wikicrawler-api:step5-python   *:5000->5000/tcp
ujj9wuvxvjli        wikistack_redis     replicated          1/1        redis:latest
zkro0rgs8u29        wikistack_web       replicated          1/1        wikicrawler-web:step5-php      *:80->80/tcp
[node1] (local) root@192.168.0.22 ~/test/test
$